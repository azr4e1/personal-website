+++
toc = true
title = "Big O Notation"
author = "Lorenzo Drumond"
date = "2024-08-13T22:27:11"
tags = ["computer_science",  "boot_dev",  "big_o",  "programming",  "algorithm",  "notation"]
+++



There are lots of existing algorithms; some are fast and some are slow. Some use lots of memory. It can be hard to decide which algorithm is the best to solve a particular problem. "Big O" analysis (pronounced "Big Oh", not "Big Zero") is one way to compare algorithms.

   Big O is a characterization of algorithms according to their worst-case growth rates

We write Big-O notation like this:

```
O(formula)
```

Where formula describes how an algorithm's run time or space requirements grow as the input size grows.

1. O(1) - constant
2. O(n) - linear
3. O(n^2) - squared
4. O(2^n) - exponential
5. O(n!) - factorial


## References

Next -> [big-o-notation-formal-definition](/wiki/big-o-notation-formal-definition/)

Next -> [big-o-summary](/wiki/big-o-summary/)
