+++
toc = true
title = "Bayesian Inference - Probability Distributions"
author = "Lorenzo Drumond"
date = "2024-10-02T17:29:40"
tags = ["bayesian",  "machine_learning",  "introduction",  "probabilistic",  "distribution",  "programming",  "statistics",  "pymc",  "inference",  "hacker"]
+++



Let Z be some random variable. Then associated with Z is a probability distribution function that assigns probabilities to the different outcomes Z can take. Graphically, a probability distribution is a curve where the probability of an outcome is proportional to the height of the curve.

We can divide random variables into three classifications:

1. Z is **discrete**: Discrete random variables may only assume values on a specified list. Things like populations, movie ratings, and number of votes are all discrete random variables. Discrete random variables become more clear when we contrast them with...
2. Z is **continuous**: Continuous random variable can take on arbitrarily exact values. For example, temperature, speed, time, color are all modeled as continuous variables because you can progressively make the values more and more precise.
3. Z is **mixed**: Mixed random variables assign probabilities to both discrete and continuous random variables, i.e. it is a combination of the above two categories.

## References

Next -> [bayesian-inference---discrete-distributions](/wiki/bayesian-inference---discrete-distributions/)
